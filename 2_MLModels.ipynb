{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QUkIv_GUw6p",
        "outputId": "c53b99c5-c9b5-4e69-cb2b-5ae42db9f4f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 33120 entries, 0 to 33119\n",
            "Data columns (total 66 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   BILIRUBIN_SLOPE           33095 non-null  float64\n",
            " 1   ALBUMIN_SLOPE             32335 non-null  float64\n",
            " 2   SERUM_SODIUM_SLOPE        33095 non-null  float64\n",
            " 3   INR_SLOPE                 33095 non-null  float64\n",
            " 4   SERUM_CREAT_SLOPE         33095 non-null  float64\n",
            " 5   AGE                       33120 non-null  float64\n",
            " 6   BMI_CALC                  33113 non-null  float64\n",
            " 7   HGT_CM_CALC               33120 non-null  float64\n",
            " 8   INIT_WGT_KG               33120 non-null  float64\n",
            " 9   INIT_ALBUMIN              33108 non-null  float64\n",
            " 10  FINAL_ALBUMIN             33117 non-null  float64\n",
            " 11  INIT_BILIRUBIN            33108 non-null  float64\n",
            " 12  FINAL_BILIRUBIN           33117 non-null  float64\n",
            " 13  INIT_ENCEPH               33120 non-null  float64\n",
            " 14  FINAL_ENCEPH              33117 non-null  float64\n",
            " 15  INIT_INR                  33108 non-null  float64\n",
            " 16  FINAL_INR                 33117 non-null  float64\n",
            " 17  INIT_SERUM_CREAT          33108 non-null  float64\n",
            " 18  FINAL_SERUM_CREAT         33117 non-null  float64\n",
            " 19  INIT_SERUM_SODIUM         33108 non-null  float64\n",
            " 20  FINAL_SERUM_SODIUM        33117 non-null  float64\n",
            " 21  INIT_MELD_PELD_LAB_SCORE  33108 non-null  float64\n",
            " 22  MELD_PELD_LAB_SCORE       33120 non-null  float64\n",
            " 23  DAYSWAIT_CHRON            33120 non-null  float64\n",
            " 24  CREAT                     11765 non-null  float64\n",
            " 25  TBILI                     11751 non-null  float64\n",
            " 26  180_OUTCOME               33120 non-null  int64  \n",
            " 27  ABO_A                     33120 non-null  bool   \n",
            " 28  ABO_AB                    33120 non-null  bool   \n",
            " 29  ABO_B                     33120 non-null  bool   \n",
            " 30  ABO_O                     33120 non-null  bool   \n",
            " 31  HCC_DIAGNOSIS_TCR_N       33120 non-null  bool   \n",
            " 32  HCC_DIAGNOSIS_TCR_Y       33120 non-null  bool   \n",
            " 33  GENDER_F                  33120 non-null  bool   \n",
            " 34  GENDER_M                  33120 non-null  bool   \n",
            " 35  PREV_AB_SURG_TCR_N        33120 non-null  bool   \n",
            " 36  PREV_AB_SURG_TCR_U        33120 non-null  bool   \n",
            " 37  PREV_AB_SURG_TCR_Y        33120 non-null  bool   \n",
            " 38  HBSAG_N                   33120 non-null  bool   \n",
            " 39  HBSAG_ND                  33120 non-null  bool   \n",
            " 40  HBSAG_P                   33120 non-null  bool   \n",
            " 41  HBSAG_U                   33120 non-null  bool   \n",
            " 42  HBV_CORE_N                33120 non-null  bool   \n",
            " 43  HBV_CORE_ND               33120 non-null  bool   \n",
            " 44  HBV_CORE_P                33120 non-null  bool   \n",
            " 45  HBV_CORE_U                33120 non-null  bool   \n",
            " 46  HBV_DNA_N                 33120 non-null  bool   \n",
            " 47  HBV_DNA_ND                33120 non-null  bool   \n",
            " 48  HBV_DNA_P                 33120 non-null  bool   \n",
            " 49  HBV_DNA_U                 33120 non-null  bool   \n",
            " 50  HCV_NAT_N                 33120 non-null  bool   \n",
            " 51  HCV_NAT_ND                33120 non-null  bool   \n",
            " 52  HCV_NAT_P                 33120 non-null  bool   \n",
            " 53  HCV_NAT_U                 33120 non-null  bool   \n",
            " 54  HCV_SEROLOGY_N            33120 non-null  bool   \n",
            " 55  HCV_SEROLOGY_ND           33120 non-null  bool   \n",
            " 56  HCV_SEROLOGY_P            33120 non-null  bool   \n",
            " 57  HCV_SEROLOGY_U            33120 non-null  bool   \n",
            " 58  HIV_NAT_N                 33120 non-null  bool   \n",
            " 59  HIV_NAT_ND                33120 non-null  bool   \n",
            " 60  HIV_NAT_P                 33120 non-null  bool   \n",
            " 61  HIV_NAT_U                 33120 non-null  bool   \n",
            " 62  HIV_SEROLOGY_N            33120 non-null  bool   \n",
            " 63  HIV_SEROLOGY_ND           33120 non-null  bool   \n",
            " 64  HIV_SEROLOGY_P            33120 non-null  bool   \n",
            " 65  HIV_SEROLOGY_U            33120 non-null  bool   \n",
            "dtypes: bool(39), float64(26), int64(1)\n",
            "memory usage: 8.3 MB\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "final_180 = pd.read_csv(\"/content/drive/MyDrive/Borealis AI/Dataset/final_180 (2).csv\", index_col = 0)\n",
        "final_180 = final_180[['BILIRUBIN_SLOPE', 'ALBUMIN_SLOPE', 'SERUM_SODIUM_SLOPE', 'INR_SLOPE',\n",
        "       'SERUM_CREAT_SLOPE', 'AGE', 'BMI_CALC', 'HGT_CM_CALC', 'INIT_WGT_KG', 'INIT_ALBUMIN',\n",
        "       'FINAL_ALBUMIN', 'INIT_BILIRUBIN', 'FINAL_BILIRUBIN', 'INIT_ENCEPH',\n",
        "       'FINAL_ENCEPH', 'INIT_INR', 'FINAL_INR', 'INIT_SERUM_CREAT',\n",
        "       'FINAL_SERUM_CREAT', 'INIT_SERUM_SODIUM', 'FINAL_SERUM_SODIUM',\n",
        "       'INIT_MELD_PELD_LAB_SCORE', 'MELD_PELD_LAB_SCORE', 'DAYSWAIT_CHRON',\n",
        "       'ABO', 'HCC_DIAGNOSIS_TCR', 'GENDER',\n",
        "       'PREV_AB_SURG_TCR', 'CREAT', 'HBSAG', 'HBV_CORE', 'HBV_DNA', 'HCV_NAT', 'HCV_SEROLOGY', 'HIV_NAT', 'HIV_SEROLOGY', 'TBILI', '180_OUTCOME']]\n",
        "df_dummies = pd.get_dummies(final_180)\n",
        "df_dummies.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now after reading the data files, only selecting relevant features, we can perform one-hot encoding to get dummy variables (performed above).\n",
        "\n",
        "We then separate train and test dataset, and scale both of them.\n",
        "\n",
        "We also use KNN imptuer to fill out missing values from the data."
      ],
      "metadata": {
        "id": "wbjWDTI6iAee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# value of TBILI is missing, so we only filter out patiens that we have the value of TBILI.\n",
        "tmp = df_dummies[~df_dummies['TBILI'].isna()]\n",
        "X = tmp.drop(['180_OUTCOME'], axis = 1)\n",
        "y = tmp['180_OUTCOME']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "imputer = KNNImputer(n_neighbors = 5)\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "sgVuEUU7iNEj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwmTqojOkF7d",
        "outputId": "c9de4008-c530-47e8-858b-97544a8e6e33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180_OUTCOME\n",
              "0    8962\n",
              "1     438\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also perform SMOTE technique to fix the ratio of 1 and 0's in y_train, which is currently hugely imbalanced"
      ],
      "metadata": {
        "id": "3zrTcCuej8nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "sm = SMOTE(sampling_strategy = 0.1, random_state=42)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnkkpEksj30V",
        "outputId": "d44efb23-06dc-4be7-9fe1-922085279f51"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled dataset shape Counter({0: 8962, 1: 896})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have X_train, y_train, X_test, y_test, we can create multiple machine learning models, which are:\n",
        "1. Neural networks\n",
        "2. Logistic Regression\n",
        "3. Decision Tree\n",
        "4. Random Forest\n",
        "5. XGBoost\n",
        "\n",
        "### 1. Neural Networks\n"
      ],
      "metadata": {
        "id": "gZ9nk7o8kx7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "# we increase the weight in neural networks as well\n",
        "weights = {0: 1, 1: 20}\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(256, input_dim=input_dim, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[Precision(name='precision'), Recall(name='recall'), AUC(name='auroc', curve='ROC')])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_auc', mode='max', save_best_only=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, class_weight=weights, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
        "results = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Neural Networks: \")\n",
        "print(f\"Precision: {results[1]}\")\n",
        "print(f\"Recall: {results[2]}\")\n",
        "print(f\"AUROC: {results[3]}\")\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "rC3BgT6tkvHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Logistic Regression"
      ],
      "metadata": {
        "id": "cqkPnuiZmEta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score, make_scorer\n",
        "\n",
        "\n",
        "classifier = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "scorers = {\n",
        "    'precision_score': make_scorer(precision_score),\n",
        "    'recall_score': make_scorer(recall_score),\n",
        "    'roc_auc_score': make_scorer(roc_auc_score, needs_proba=True)\n",
        "}\n",
        "\n",
        "clf = GridSearchCV(classifier, param_grid, scoring=scorers, refit='roc_auc_score', return_train_score=True, cv=3)\n",
        "clf.fit(X_train, y_train)\n",
        "best_model = clf.best_estimator_\n",
        "\n",
        "y_probs = best_model.predict_proba(X_test)[:, 1]\n",
        "y_pred = best_model.predict(X_test)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "\n",
        "print(\"Logistic Regression: \")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"ROC AUC Score: {roc_auc}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "nqe_iZa8mGjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Decision tree"
      ],
      "metadata": {
        "id": "tGGUitwamIqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state = 42)\n",
        "forest = RandomForestClassifier(random_state = 42)\n",
        "\n",
        "param_grid_tree = [\n",
        "    {\n",
        "        'max_depth': list(range(1, 10)),\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    }\n",
        "]\n",
        "\n",
        "gcv_tree = GridSearchCV(estimator=tree,\n",
        "                       param_grid=param_grid_tree,\n",
        "                       scoring='f1',\n",
        "                       n_jobs=-1,\n",
        "                       cv=5,\n",
        "                       verbose=0,\n",
        "                       refit=True)\n",
        "gcv_tree.fit(X_train, y_train)\n",
        "tree = gcv_tree.best_estimator_\n",
        "\n",
        "y_probs = tree.predict_proba(X_test)[:, 1]\n",
        "y_pred = tree.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "\n",
        "print(\"Decision Tree:\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"ROC AUC Score: {roc_auc}\")\n",
        "print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "0JXPXcCxmKUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Random Forest"
      ],
      "metadata": {
        "id": "lha_StiXmOFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier(random_state = 42)\n",
        "new_param_grid_forest = [\n",
        "    {\n",
        "        'n_estimators': [5, 10, 25],  # Increased number of estimators\n",
        "        'max_features': ['auto', 'sqrt'],\n",
        "        'max_depth': [None, 10, 30],  # Additional depths to explore\n",
        "        'min_samples_split': [2, 5, 10],  # Adding min_samples_split\n",
        "        'min_samples_leaf': [1, 2, 4],    # Adding min_samples_leaf\n",
        "        'bootstrap': [True, False],       # Considering both bootstrap options\n",
        "        'class_weight': [None, 'balanced', 'balanced_subsample']  # Adding class_weight\n",
        "    }\n",
        "]\n",
        "\n",
        "new_gcv_forest = GridSearchCV(estimator=forest,\n",
        "                          param_grid=new_param_grid_forest,\n",
        "                          scoring='f1',  # Changed to f1 score\n",
        "                          n_jobs=-1,\n",
        "                          cv=5,\n",
        "                          verbose=0,\n",
        "                          refit=True)\n",
        "\n",
        "new_gcv_forest.fit(X_train, y_train)\n",
        "forest = new_gcv_forest.best_estimator_\n",
        "\n",
        "y_probs = forest.predict_proba(X_test)[:, 1]\n",
        "y_pred = forest.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "\n",
        "print(\"Random Forest:\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"ROC AUC Score: {roc_auc}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "PYatjsujmPJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. XGBoost"
      ],
      "metadata": {
        "id": "lgPgGRYOmdF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(scale_pos_weight=10, use_label_encoder=False, eval_metric='logloss')\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'subsample': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "clf = GridSearchCV(xgb_model, param_grid, scoring=scorers, refit='roc_auc_score', return_train_score=True, cv=3)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "best_model = clf.best_estimator_\n",
        "\n",
        "y_probs = best_model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "\n",
        "\n",
        "\n",
        "print(\"XGBoost: \")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"ROC AUC Score: {roc_auc}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "AM0LJsK7mdcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can combine these results to compare the accuracy / performance of different ML models."
      ],
      "metadata": {
        "id": "b0TMHAqkoV0X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zgf8zNMgoa8M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}